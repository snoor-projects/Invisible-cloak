{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invisible cloak using OpenCV\n",
    "\n",
    "The key idea is to replace the current frame pixels corresponding to the cloth/cloak \n",
    "with the background pixels to generate the effect of an invisibility cloak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the opencv library, if not installed\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2          # OpenCV library\n",
    "import numpy as np  # Numpy library used to deal with the arrays\n",
    "import time         # Time library to use sleep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Record/Upload video and store background for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from the video, insert your video title instead of video.mp4\n",
    "# Incase you want to read from webcam use cv2.VideoCapture(0)\n",
    "input_video = cv2.VideoCapture(\"video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the webcam start by giving it 2 seconds\n",
    "time.sleep(2) \n",
    "count = 0 \n",
    "background = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing the background in range of 30 (depends on your video)\n",
    "for i in range(30):\n",
    "\trval , background = input_video.read()\n",
    "\tif rval == False :\n",
    "\t\tcontinue \n",
    "# Laterally invert the image / flip the image\n",
    "background = np.flip(background,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detect the defined color portion and replace with the mask image in each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read every frame from the video/webcam, until the video is open \n",
    "while (input_video.isOpened()):\n",
    "\trval, img = input_video.read()\n",
    "\tif not rval :\n",
    "\t\tbreak \n",
    "\tcount = count + 1\n",
    "\timg = np.flip(img , axis=1)\n",
    "    \n",
    "\t# Convert the image from BGR(Blue, Green, Red) to HSV(Hue, Saturation, Value) \n",
    "\thsv = cv2.cvtColor(img , cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "\t# Generate mask to detect red color\n",
    "    # You can choose any other color cloth also, you just need to change the HSV values.\n",
    "    \n",
    "    # Range for lower red\n",
    "\tlower_red = np.array([100, 40, 40])\n",
    "\tupper_red = np.array([100, 255, 255])\n",
    "\tmask1 = cv2.inRange(hsv,lower_red,upper_red)\n",
    "\n",
    "    # Range for upper red\n",
    "\tlower_red = np.array([155, 40, 40])\n",
    "\tupper_red = np.array([180, 255, 255])\n",
    "\tmask2 = cv2.inRange(hsv,lower_red,upper_red)\n",
    "    \n",
    "    # Using the below line, we combine masks generated for both the red color range.\n",
    "\tmask1 = mask1+mask2\n",
    "\n",
    "    # Refining the mask corresponding to the detected red color\n",
    "    # Open and dilate the mask image\n",
    "\tmask1 = cv2.morphologyEx(mask1, cv2.MORPH_OPEN, np.ones((3,3),np.uint8),iterations=2)\n",
    "\tmask1 = cv2.dilate(mask1,np.ones((3,3),np.uint8),iterations = 1)\n",
    "    \n",
    "    # Create an inverted mask to segment out the red color from the frame\n",
    "\tmask2 = cv2.bitwise_not(mask1)\n",
    "\n",
    "    # Segment the red color part out of the frame using bitwise and with the inverted mask\n",
    "\tres1 = cv2.bitwise_and(background,background,mask=mask1)\n",
    "    \n",
    "    # Create image showing static background frame pixels only for the masked region\n",
    "\tres2 = cv2.bitwise_and(img,img,mask=mask2)\n",
    "    \n",
    "    # Generating the final output\n",
    "\toutput_video = cv2.addWeighted(res1,1,res2,1,0)\n",
    "    \n",
    "    # Show the output video with title 'Let's be invisble'\n",
    "\tcv2.imshow(\"Let's be invisble\",output_video)\n",
    "\tk = cv2.waitKey(10)\n",
    "\tif k == 27: #esc key\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close your video window\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
